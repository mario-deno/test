{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.regularizers import l2, l1\n",
    "from keras import optimizers\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = VGG16(weights='imagenet', include_top=False,  input_shape=(256, 256, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the layers which you don't want to train. Here I am freezing the first 5 layers.\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /src/keras/backend/tensorflow_backend.py:3680: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "x=model.output #?? quanti layer densi devo usare? e con quale numero di neuroni\n",
    "x=Flatten(input_shape=model.output_shape[1:])(x)\n",
    "x=Dense(256, activation='relu',  kernel_regularizer=l2(0.01))(x)\n",
    "x=Dropout(0.5)(x)\n",
    "preds=Dense(1, activation='sigmoid')(x) #dovrei usare softmax con due neuroni come output??\n",
    "\n",
    "final_model=Model(inputs=model.input,outputs=preds)\n",
    "#specify the inputs\n",
    "#specify the outputs\n",
    "#now a model has been created based on our architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1840 images belonging to 2 classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A DirectoryIterator yielding tuples of (x, y) where x is a numpy array containing a batch of \\nimages with shape (batch_size (a.k.a. # of images), target_size, channels) \\nand y is a numpy array of corresponding labels.\\n\\nexample of image 2x2 \\n[BATCH\\n    [   IMAGE1\\n        [    ROW1\\n            [r,g,b pixel (1,1)] , [r,g,b pixel(1,2)]\\n        ],\\n        [    ROW2\\n            [r,g,b pixel (1,2)] , [r,g,b pixel(2,2)]\\n        ]\\n    ],\\n    [   IMAGE2\\n        .....\\n    ]\\n]\\n\\nbatches[0] ->  x the numpy array \\nbatches[0][0] -> first image\\nbatches[0][1] -> second image\\nbatches[0][0][0] -> first image first row\\nbatches[0][0][0][0] -> first image first row first pixel (rgb)\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255) #divide all pixel value for 225\n",
    "\n",
    "\n",
    "#questo generator sembra creare immagini custom a partire dalla cartella specificata\n",
    "train_generator=train_datagen.flow_from_directory('car-damage-dataset/data1a/training',\n",
    "                                                 target_size=(256,256),\n",
    "                                                 color_mode='rgb',\n",
    "                                                 batch_size=20, #number of images for cycle\n",
    "                                                 class_mode='binary',\n",
    "                                                 shuffle=False)\n",
    "\n",
    "\n",
    "'''A DirectoryIterator yielding tuples of (x, y) where x is a numpy array containing a batch of \n",
    "images with shape (batch_size (a.k.a. # of images), target_size, channels) \n",
    "and y is a numpy array of corresponding labels.\n",
    "\n",
    "example of image 2x2 \n",
    "[BATCH\n",
    "    [   IMAGE1\n",
    "        [    ROW1\n",
    "            [r,g,b pixel (1,1)] , [r,g,b pixel(1,2)]\n",
    "        ],\n",
    "        [    ROW2\n",
    "            [r,g,b pixel (1,2)] , [r,g,b pixel(2,2)]\n",
    "        ]\n",
    "    ],\n",
    "    [   IMAGE2\n",
    "        .....\n",
    "    ]\n",
    "]\n",
    "\n",
    "batches[0] ->  x the numpy array \n",
    "batches[0][0] -> first image\n",
    "batches[0][1] -> second image\n",
    "batches[0][0][0] -> first image first row\n",
    "batches[0][0][0][0] -> first image first row first pixel (rgb)\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 460 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_datagen = ImageDataGenerator(rescale=1./255) #divide all pixel value for 225\n",
    "\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory('car-damage-dataset/data1a/validation',\n",
    "                                                           target_size=(256,256),\n",
    "                                                           color_mode='rgb',\n",
    "                                                           batch_size=20, #number of images for cycle\n",
    "                                                           class_mode='binary',\n",
    "                                                           shuffle=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_train_samples = train_generator.n//train_generator.batch_size #number of image / batch size \n",
    "nb_validation_samples = validation_generator.n // validation_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.compile(loss='binary_crossentropy', optimizer=optimizers.SGD(lr=0.0001, momentum=0.9), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "92/92 [==============================] - 1950s 21s/step - loss: 5.8468 - acc: 0.5978 - val_loss: 5.6157 - val_acc: 0.8326\n"
     ]
    }
   ],
   "source": [
    "fit_history = final_model.fit_generator(train_generator,\n",
    "                          steps_per_epoch=nb_train_samples,\n",
    "                          epochs=1,\n",
    "                          validation_data=validation_generator,\n",
    "                          validation_steps=nb_validation_samples,\n",
    "                          verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "for batches in train_generator:\n",
    "        i += 1\n",
    "        if i > 1:\n",
    "            # we need to break the loop by hand because\n",
    "            # the generator loops indefinitely\n",
    "            break\n",
    "        #print(batches[0][0])\n",
    "        #print(batches[1][0])\n",
    "        img = Image.fromarray(batches[0][0], 'RGB')\n",
    "        display(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
